## W4M3 - Crawling a billion web pages in just over 24 hours, in 2025

주어진 링크의 포스트를 읽고 팀원들과 논의하고 배운 내용을 정리합니다.
- 어떤 내용이 가장 인상적이었나요?
- 아키텍처에 대해 논의합니다.
- 어떤 의사결정이 놀라웠나요?
---
무분별한 크롤링으로 인해 매주 수십 건의 짧은 서비스 중단이 발생하기도, 사용자와 봇을 항상 확실하게 구분하는 데 비용이 들기도, 컴퓨팅 자원의 사용으로 환경이 파괴되기도, 저작권 개념 없이 데이터를 무분별하게 수집할 수도 있다는 점을 깨달았다.  
이 포스트에서는 이를 고려해, robots.txt를 준수하는 등 이러한 부작용을 고려해 문제가 생기지 않도록 했다.  

### 아키텍처 관련
파싱용 머신, fetch용 머신, 데이터 저장용 머신을 분리해 두지 않고 
12개의 독립 노드들이 모든 크롤러 기능을 포함하도록 했다.  
    이유: 예산이 한정적  
    작게 시작해서 하나의 기계에 모든 기능을 넣은 다음 규모를 키웠음  
처음엔 단일 머신 성능의 극대화가 목표였다.  
    과거에 큰 크롤링 시 하드웨어 병목 현상이 문제였기 때문 -> 하나의 aws i7i.4xlarge머신에 묶고 실행했으나 결과가 실망스러움 -> 시간이 부족해 이 방법 대신 수평 확장으로 전환  
아키텍처 그림: 데이터가 저장된 redis를 중심으로 fetcher, pasher와 소통하며 동작  
한계점: 도메인 시드 목록(노드들이 처리할 도메인 url 목록)이 서로 공유되지 않아, 노드들은 자신에게 할당된 도메인 목록만 크롤링을 수행  
    노드 개수를 12개라는 최적의 수를 두어, 특정 노드에게만 많은 작업이 부과되는 걸 방지하긴 함  

### 문제 상황 관련  
파싱이 큰 병목현상이었다.  
-> 라이브러리를 lxml에서 selectolax(최신 웹 상황 반영)로 바꿔 해결, 파서에 전달하기 전 웹 페이지 콘텐츠를 줄여서 전달함  
  
Fetch - 가져오기 쉬운 것도, 어려운 것도 있다.  
전체 네트워크 대역폭을 피하기 위해 크롤링 처리량 조절이 필요 + DNS 확인 처리에 병목 발생 -> 이 부분은 실행 결과 큰 문제가 아니었음. 크롤링 시 dns가 전혀 표시되지 않았으므로  
다만, ssl(웹사이트 보안 기술) handshake 계산이 cpu를 많이 사용해 병목 발생 -> 이 부분은 어떻게 해결했는지에 대한 설명 없음  
  
메모리 문제: 메모리가 특정 인기 도메인의 프런티어(웹사이트 내 수많은 url)를 감당하지 못하고 노드들이 죽음  
다행히 fault tolerance(장애가 발생해도 작업을 재개)로 해결  

### 의사결정 관련
1. 예산이 한정적이라, 12개의 독립 노드들이 모든 크롤러 기능을 포함하도록 함
2. 처음엔 단일 머신 성능의 극대화가 목표였으나, 결과가 실망스러웠으며 시간이 부족해 수평 확장으로 목표를 전환
3. 파싱에서 병목 현상을 완화하기 위해, 라이브러리를 lxml에서 selectolax(최신 웹 상황 반영)로 바꿔 해결, 파서에 전달하기 전 웹 페이지 콘텐츠를 줄여서 전달  
이 중 2번 의사결정을 보며, 처음 목표 달성이 쉽지 않아 보일 때, 주어진 상황을 고려해 차선책을 마련해 실행하는 점이 인상적이었다.
